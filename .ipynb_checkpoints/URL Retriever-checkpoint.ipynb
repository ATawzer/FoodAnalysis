{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from recipe_scrapers import scrape_me\n",
    "import time\n",
    "import random\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def wait():\n",
    "    \n",
    "    x = random.randrange(2, 12, 1)\n",
    "    print(f\"Waiting for {x} Seconds.\", end='\\r')\n",
    "    time.sleep(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# My Baking Addiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# My Baking Addiction\n",
    "starting = 'https://www.mybakingaddiction.com/cookies/page/'\n",
    "dnew = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Obtain links to scrape for recipe urls\n",
    "index = scrape_me('https://www.mybakingaddiction.com/recipe-index/').links()\n",
    "starting = []\n",
    "for link in index[26:]:\n",
    "    if link['href'] != '/about/':\n",
    "        starting.append(link['href']+'page/')\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Extract Recipe URLS function\n",
    "def mybakingaddiction_extract_urls(starting, save_dict):\n",
    "    for i in range(1, 100):\n",
    "        try:\n",
    "            print(\"Scraping \"+starting+str(i))\n",
    "            page = scrape_me(starting+str(i))\n",
    "            wait()\n",
    "            \n",
    "            # Check if page is blank\n",
    "            if len(page.links()[26:]) > 43:\n",
    "                for link in page.links()[26:]:\n",
    "                    if '/page/' in link['href']:\n",
    "                        break\n",
    "                    save_dict[link['href']] = 0\n",
    "            else:\n",
    "                break\n",
    "        except:\n",
    "            break\n",
    "    return save_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping https://www.mybakingaddiction.com/appetizers/page/1\n",
      "Scraping https://www.mybakingaddiction.com/appetizers/page/2\n",
      "Scraping https://www.mybakingaddiction.com/appetizers/page/3\n",
      "Scraping https://www.mybakingaddiction.com/appetizers/page/4\n",
      "Scraping https://www.mybakingaddiction.com/bar-desserts/page/1\n",
      "Scraping https://www.mybakingaddiction.com/bar-desserts/page/2\n",
      "Scraping https://www.mybakingaddiction.com/bar-desserts/page/3\n",
      "Scraping https://www.mybakingaddiction.com/bar-desserts/page/4\n",
      "Scraping https://www.mybakingaddiction.com/bar-desserts/page/5\n",
      "Scraping https://www.mybakingaddiction.com/bar-desserts/page/6\n",
      "Scraping https://www.mybakingaddiction.com/beverages/page/1\n",
      "Scraping https://www.mybakingaddiction.com/beverages/page/2\n",
      "Scraping https://www.mybakingaddiction.com/beverages/page/3\n",
      "Scraping https://www.mybakingaddiction.com/breakfast/page/1\n",
      "Scraping https://www.mybakingaddiction.com/breakfast/page/2\n",
      "Scraping https://www.mybakingaddiction.com/breakfast/page/3\n",
      "Scraping https://www.mybakingaddiction.com/breakfast/page/4\n",
      "Scraping https://www.mybakingaddiction.com/breakfast/page/5\n",
      "Scraping https://www.mybakingaddiction.com/breakfast/page/6\n",
      "Scraping https://www.mybakingaddiction.com/breakfast/page/7\n",
      "Scraping https://www.mybakingaddiction.com/cake/page/1\n",
      "Scraping https://www.mybakingaddiction.com/cake/page/2\n",
      "Scraping https://www.mybakingaddiction.com/cake/page/3\n",
      "Scraping https://www.mybakingaddiction.com/cake/page/4\n",
      "Scraping https://www.mybakingaddiction.com/cake/page/5\n",
      "Scraping https://www.mybakingaddiction.com/cake/page/6\n",
      "Scraping https://www.mybakingaddiction.com/cake/page/7\n",
      "Scraping https://www.mybakingaddiction.com/cake/page/8\n",
      "Scraping https://www.mybakingaddiction.com/cake/page/9\n",
      "Scraping https://www.mybakingaddiction.com/cake/page/10\n",
      "Scraping https://www.mybakingaddiction.com/candy/page/1\n",
      "Scraping https://www.mybakingaddiction.com/candy/page/2\n",
      "Scraping https://www.mybakingaddiction.com/candy/page/3\n",
      "Scraping https://www.mybakingaddiction.com/candy/page/4\n",
      "Scraping https://www.mybakingaddiction.com/cheesecake/page/1\n",
      "Scraping https://www.mybakingaddiction.com/cheesecake/page/2\n",
      "Scraping https://www.mybakingaddiction.com/cheesecake/page/3\n",
      "Scraping https://www.mybakingaddiction.com/cheesecake/page/4\n",
      "Scraping https://www.mybakingaddiction.com/cheesecake/page/5\n",
      "Scraping https://www.mybakingaddiction.com/cookies/page/1\n",
      "Scraping https://www.mybakingaddiction.com/cookies/page/2\n",
      "Scraping https://www.mybakingaddiction.com/cookies/page/3\n",
      "Scraping https://www.mybakingaddiction.com/cookies/page/4\n",
      "Scraping https://www.mybakingaddiction.com/cookies/page/5\n",
      "Scraping https://www.mybakingaddiction.com/cookies/page/6\n",
      "Scraping https://www.mybakingaddiction.com/cookies/page/7\n",
      "Scraping https://www.mybakingaddiction.com/cookies/page/8\n",
      "Scraping https://www.mybakingaddiction.com/cookies/page/9\n",
      "Scraping https://www.mybakingaddiction.com/cookies/page/10\n",
      "Scraping https://www.mybakingaddiction.com/dinner/page/1\n",
      "Scraping https://www.mybakingaddiction.com/dinner/page/2\n",
      "Scraping https://www.mybakingaddiction.com/dinner/page/3\n",
      "Scraping https://www.mybakingaddiction.com/dinner/page/4\n",
      "Scraping https://www.mybakingaddiction.com/dinner/page/5\n",
      "Scraping https://www.mybakingaddiction.com/frozen-desserts/page/1\n",
      "Scraping https://www.mybakingaddiction.com/frozen-desserts/page/2\n",
      "Scraping https://www.mybakingaddiction.com/frozen-desserts/page/3\n",
      "Scraping https://www.mybakingaddiction.com/miscellaneous/page/1\n",
      "Scraping https://www.mybakingaddiction.com/miscellaneous/page/2\n",
      "Scraping https://www.mybakingaddiction.com/miscellaneous/page/3\n",
      "Scraping https://www.mybakingaddiction.com/miscellaneous/page/4\n",
      "Scraping https://www.mybakingaddiction.com/no-bake-2/page/1\n",
      "Scraping https://www.mybakingaddiction.com/no-bake-2/page/2\n",
      "Scraping https://www.mybakingaddiction.com/no-bake-2/page/3\n",
      "Scraping https://www.mybakingaddiction.com/no-bake-2/page/4\n",
      "Scraping https://www.mybakingaddiction.com/quick-bread/page/1\n",
      "Scraping https://www.mybakingaddiction.com/quick-bread/page/2\n",
      "Scraping https://www.mybakingaddiction.com/quick-bread/page/3\n",
      "Scraping https://www.mybakingaddiction.com/yeast-bread/page/1\n",
      "Scraping https://www.mybakingaddiction.com/yeast-bread/page/2\n",
      "Waiting for 7 Seconds.\r"
     ]
    }
   ],
   "source": [
    "# Run through each recipe index page and gather all recipes\n",
    "for start in starting:\n",
    "    \n",
    "    recipe_type = start.split('www.mybakingaddiction.com/')[1].split('/page/')[0]\n",
    "    dnew[recipe_type] = {}\n",
    "    dnew[recipe_type] = mybakingaddiction_extract_urls(start, dnew[recipe_type])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Save\n",
    "with open('my_baking_addiction_scraped.json', 'w') as json_file:\n",
    "    json.dump(dnew, json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Southern Living"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Southern Living\n",
    "dnew = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping https://www.southernliving.com/recipes?page=2\n",
      "Scraping https://www.southernliving.com/recipes?page=3\n",
      "Scraping https://www.southernliving.com/recipes?page=4\n",
      "Scraping https://www.southernliving.com/recipes?page=5\n",
      "Scraping https://www.southernliving.com/recipes?page=6\n",
      "Scraping https://www.southernliving.com/recipes?page=7\n",
      "Scraping https://www.southernliving.com/recipes?page=8\n",
      "Scraping https://www.southernliving.com/recipes?page=9\n",
      "Scraping https://www.southernliving.com/recipes?page=10\n",
      "Scraping https://www.southernliving.com/recipes?page=11\n",
      "Scraping https://www.southernliving.com/recipes?page=12\n",
      "Scraping https://www.southernliving.com/recipes?page=13\n",
      "Scraping https://www.southernliving.com/recipes?page=14\n",
      "Scraping https://www.southernliving.com/recipes?page=15\n",
      "Scraping https://www.southernliving.com/recipes?page=16\n",
      "Scraping https://www.southernliving.com/recipes?page=17\n",
      "Scraping https://www.southernliving.com/recipes?page=18\n",
      "Scraping https://www.southernliving.com/recipes?page=19\n",
      "Scraping https://www.southernliving.com/recipes?page=20\n",
      "Scraping https://www.southernliving.com/recipes?page=21\n",
      "Scraping https://www.southernliving.com/recipes?page=22\n",
      "Scraping https://www.southernliving.com/recipes?page=23\n",
      "Scraping https://www.southernliving.com/recipes?page=24\n",
      "Scraping https://www.southernliving.com/recipes?page=25\n",
      "Scraping https://www.southernliving.com/recipes?page=26\n",
      "Scraping https://www.southernliving.com/recipes?page=27\n",
      "Scraping https://www.southernliving.com/recipes?page=28\n",
      "Scraping https://www.southernliving.com/recipes?page=29\n",
      "Scraping https://www.southernliving.com/recipes?page=30\n",
      "Scraping https://www.southernliving.com/recipes?page=31\n",
      "Scraping https://www.southernliving.com/recipes?page=32\n",
      "Scraping https://www.southernliving.com/recipes?page=33\n",
      "Scraping https://www.southernliving.com/recipes?page=34\n",
      "Scraping https://www.southernliving.com/recipes?page=35\n",
      "Scraping https://www.southernliving.com/recipes?page=36\n",
      "Scraping https://www.southernliving.com/recipes?page=37\n",
      "Scraping https://www.southernliving.com/recipes?page=38\n",
      "Scraping https://www.southernliving.com/recipes?page=39\n",
      "Scraping https://www.southernliving.com/recipes?page=40\n",
      "Scraping https://www.southernliving.com/recipes?page=41\n",
      "Scraping https://www.southernliving.com/recipes?page=42\n",
      "Scraping https://www.southernliving.com/recipes?page=43\n",
      "Scraping https://www.southernliving.com/recipes?page=44\n",
      "Scraping https://www.southernliving.com/recipes?page=45\n",
      "Scraping https://www.southernliving.com/recipes?page=46\n",
      "Scraping https://www.southernliving.com/recipes?page=47\n",
      "Scraping https://www.southernliving.com/recipes?page=48\n",
      "Scraping https://www.southernliving.com/recipes?page=49\n",
      "Scraping https://www.southernliving.com/recipes?page=50\n",
      "Scraping https://www.southernliving.com/recipes?page=51\n",
      "Scraping https://www.southernliving.com/recipes?page=52\n",
      "Scraping https://www.southernliving.com/recipes?page=53\n",
      "Scraping https://www.southernliving.com/recipes?page=54\n",
      "Scraping https://www.southernliving.com/recipes?page=55\n",
      "Scraping https://www.southernliving.com/recipes?page=56\n",
      "Scraping https://www.southernliving.com/recipes?page=57\n",
      "Scraping https://www.southernliving.com/recipes?page=58\n",
      "Scraping https://www.southernliving.com/recipes?page=59\n",
      "Scraping https://www.southernliving.com/recipes?page=60\n",
      "Scraping https://www.southernliving.com/recipes?page=61\n",
      "Scraping https://www.southernliving.com/recipes?page=62\n",
      "Scraping https://www.southernliving.com/recipes?page=63\n",
      "Scraping https://www.southernliving.com/recipes?page=64\n",
      "Scraping https://www.southernliving.com/recipes?page=65\n",
      "Scraping https://www.southernliving.com/recipes?page=66\n",
      "Scraping https://www.southernliving.com/recipes?page=67\n",
      "Scraping https://www.southernliving.com/recipes?page=68\n",
      "Scraping https://www.southernliving.com/recipes?page=69\n",
      "Scraping https://www.southernliving.com/recipes?page=70\n",
      "Scraping https://www.southernliving.com/recipes?page=71\n",
      "Scraping https://www.southernliving.com/recipes?page=72\n",
      "Scraping https://www.southernliving.com/recipes?page=73\n",
      "Scraping https://www.southernliving.com/recipes?page=74\n",
      "Scraping https://www.southernliving.com/recipes?page=75\n",
      "Scraping https://www.southernliving.com/recipes?page=76\n",
      "Scraping https://www.southernliving.com/recipes?page=77\n",
      "Scraping https://www.southernliving.com/recipes?page=78\n",
      "Scraping https://www.southernliving.com/recipes?page=79\n",
      "Scraping https://www.southernliving.com/recipes?page=80\n",
      "Scraping https://www.southernliving.com/recipes?page=81\n",
      "Scraping https://www.southernliving.com/recipes?page=82\n",
      "Scraping https://www.southernliving.com/recipes?page=83\n",
      "Scraping https://www.southernliving.com/recipes?page=84\n",
      "Scraping https://www.southernliving.com/recipes?page=85\n",
      "Scraping https://www.southernliving.com/recipes?page=86\n",
      "Scraping https://www.southernliving.com/recipes?page=87\n",
      "Scraping https://www.southernliving.com/recipes?page=88\n",
      "Scraping https://www.southernliving.com/recipes?page=89\n",
      "Scraping https://www.southernliving.com/recipes?page=90\n",
      "Scraping https://www.southernliving.com/recipes?page=91\n",
      "Scraping https://www.southernliving.com/recipes?page=92\n",
      "Scraping https://www.southernliving.com/recipes?page=93\n",
      "Scraping https://www.southernliving.com/recipes?page=94\n",
      "Scraping https://www.southernliving.com/recipes?page=95\n",
      "Scraping https://www.southernliving.com/recipes?page=96\n",
      "Scraping https://www.southernliving.com/recipes?page=97\n",
      "Scraping https://www.southernliving.com/recipes?page=98\n",
      "Scraping https://www.southernliving.com/recipes?page=99\n",
      "Scraping https://www.southernliving.com/recipes?page=100\n",
      "Scraping https://www.southernliving.com/recipes?page=101\n",
      "Scraping https://www.southernliving.com/recipes?page=102\n",
      "Scraping https://www.southernliving.com/recipes?page=103\n",
      "Scraping https://www.southernliving.com/recipes?page=104\n",
      "Scraping https://www.southernliving.com/recipes?page=105\n",
      "Scraping https://www.southernliving.com/recipes?page=106\n",
      "Scraping https://www.southernliving.com/recipes?page=107\n",
      "Scraping https://www.southernliving.com/recipes?page=108\n",
      "Scraping https://www.southernliving.com/recipes?page=109\n",
      "Scraping https://www.southernliving.com/recipes?page=110\n",
      "Scraping https://www.southernliving.com/recipes?page=111\n",
      "Scraping https://www.southernliving.com/recipes?page=112\n",
      "Scraping https://www.southernliving.com/recipes?page=113\n",
      "Scraping https://www.southernliving.com/recipes?page=114\n",
      "Scraping https://www.southernliving.com/recipes?page=115\n",
      "Scraping https://www.southernliving.com/recipes?page=116\n",
      "Scraping https://www.southernliving.com/recipes?page=117\n",
      "Scraping https://www.southernliving.com/recipes?page=118\n",
      "Scraping https://www.southernliving.com/recipes?page=119\n",
      "Scraping https://www.southernliving.com/recipes?page=120\n",
      "Scraping https://www.southernliving.com/recipes?page=121\n",
      "Scraping https://www.southernliving.com/recipes?page=122\n",
      "Scraping https://www.southernliving.com/recipes?page=123\n",
      "Scraping https://www.southernliving.com/recipes?page=124\n",
      "Scraping https://www.southernliving.com/recipes?page=125\n",
      "Scraping https://www.southernliving.com/recipes?page=126\n",
      "Scraping https://www.southernliving.com/recipes?page=127\n",
      "Scraping https://www.southernliving.com/recipes?page=128\n",
      "Scraping https://www.southernliving.com/recipes?page=129\n",
      "Scraping https://www.southernliving.com/recipes?page=130\n",
      "Scraping https://www.southernliving.com/recipes?page=131\n",
      "Scraping https://www.southernliving.com/recipes?page=132\n",
      "Scraping https://www.southernliving.com/recipes?page=133\n",
      "Scraping https://www.southernliving.com/recipes?page=134\n",
      "Scraping https://www.southernliving.com/recipes?page=135\n",
      "Scraping https://www.southernliving.com/recipes?page=136\n",
      "Scraping https://www.southernliving.com/recipes?page=137\n",
      "Scraping https://www.southernliving.com/recipes?page=138\n",
      "Scraping https://www.southernliving.com/recipes?page=139\n",
      "Scraping https://www.southernliving.com/recipes?page=140\n",
      "Scraping https://www.southernliving.com/recipes?page=141\n",
      "Scraping https://www.southernliving.com/recipes?page=142\n",
      "Scraping https://www.southernliving.com/recipes?page=143\n",
      "Scraping https://www.southernliving.com/recipes?page=144\n",
      "Scraping https://www.southernliving.com/recipes?page=145\n",
      "Scraping https://www.southernliving.com/recipes?page=146\n",
      "Scraping https://www.southernliving.com/recipes?page=147\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping https://www.southernliving.com/recipes?page=148\n",
      "Scraping https://www.southernliving.com/recipes?page=149\n",
      "Scraping https://www.southernliving.com/recipes?page=150\n",
      "Scraping https://www.southernliving.com/recipes?page=151\n",
      "Scraping https://www.southernliving.com/recipes?page=152\n",
      "Scraping https://www.southernliving.com/recipes?page=153\n",
      "Scraping https://www.southernliving.com/recipes?page=154\n",
      "Scraping https://www.southernliving.com/recipes?page=155\n",
      "Scraping https://www.southernliving.com/recipes?page=156\n",
      "Scraping https://www.southernliving.com/recipes?page=157\n",
      "Scraping https://www.southernliving.com/recipes?page=158\n",
      "Scraping https://www.southernliving.com/recipes?page=159\n",
      "Scraping https://www.southernliving.com/recipes?page=160\n",
      "Scraping https://www.southernliving.com/recipes?page=161\n",
      "Scraping https://www.southernliving.com/recipes?page=162\n",
      "Scraping https://www.southernliving.com/recipes?page=163\n",
      "Scraping https://www.southernliving.com/recipes?page=164\n",
      "Scraping https://www.southernliving.com/recipes?page=165\n",
      "Scraping https://www.southernliving.com/recipes?page=166\n",
      "Scraping https://www.southernliving.com/recipes?page=167\n",
      "Scraping https://www.southernliving.com/recipes?page=168\n",
      "Scraping https://www.southernliving.com/recipes?page=169\n",
      "Scraping https://www.southernliving.com/recipes?page=170\n",
      "Scraping https://www.southernliving.com/recipes?page=171\n",
      "Scraping https://www.southernliving.com/recipes?page=172\n",
      "Scraping https://www.southernliving.com/recipes?page=173\n",
      "Scraping https://www.southernliving.com/recipes?page=174\n",
      "Scraping https://www.southernliving.com/recipes?page=175\n",
      "Scraping https://www.southernliving.com/recipes?page=176\n",
      "Scraping https://www.southernliving.com/recipes?page=177\n",
      "Scraping https://www.southernliving.com/recipes?page=178\n",
      "Scraping https://www.southernliving.com/recipes?page=179\n",
      "Scraping https://www.southernliving.com/recipes?page=180\n",
      "Scraping https://www.southernliving.com/recipes?page=181\n",
      "Scraping https://www.southernliving.com/recipes?page=182\n",
      "Scraping https://www.southernliving.com/recipes?page=183\n",
      "Scraping https://www.southernliving.com/recipes?page=184\n",
      "Scraping https://www.southernliving.com/recipes?page=185\n",
      "Scraping https://www.southernliving.com/recipes?page=186\n",
      "Scraping https://www.southernliving.com/recipes?page=187\n",
      "Scraping https://www.southernliving.com/recipes?page=188\n",
      "Scraping https://www.southernliving.com/recipes?page=189\n",
      "Scraping https://www.southernliving.com/recipes?page=190\n",
      "Scraping https://www.southernliving.com/recipes?page=191\n",
      "Scraping https://www.southernliving.com/recipes?page=192\n",
      "Scraping https://www.southernliving.com/recipes?page=193\n",
      "Scraping https://www.southernliving.com/recipes?page=194\n",
      "Scraping https://www.southernliving.com/recipes?page=195\n",
      "Scraping https://www.southernliving.com/recipes?page=196\n",
      "Scraping https://www.southernliving.com/recipes?page=197\n",
      "Scraping https://www.southernliving.com/recipes?page=198\n",
      "Scraping https://www.southernliving.com/recipes?page=199\n",
      "Waiting for 24 Seconds.\r"
     ]
    }
   ],
   "source": [
    "# Easy Page structure\n",
    "for i in range(2, 200):\n",
    "    \n",
    "    page = 'https://www.southernliving.com/recipes?page='+str(i)\n",
    "    index = scrape_me(page).links()\n",
    "    print(\"Scraping \"+ page)\n",
    "    wait()\n",
    "\n",
    "    for item in index:\n",
    "        if 'class' in item.keys():\n",
    "            if 'media-img' in item['class']:\n",
    "                if 'https' not in item['href']:\n",
    "                    dnew['https://www.southernliving.com'+item['href']] = item['href'].split(\"/\")[-1].replace(\"-\", \" \")\n",
    "                    \n",
    "    # Save incrementally to avoid losing progress\n",
    "    with open('./scraped_urls/southern_living_scraped.json', 'w') as json_file:\n",
    "        json.dump(dnew, json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Food.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Build Topic List\n",
    "try:\n",
    "    topic_file = open('./scraped_urls/food_com_topics.json')\n",
    "    topics = json.load(topic_file)\n",
    "except:\n",
    "    topics = {}\n",
    "    alphabet = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
    "\n",
    "    for letter in alphabet:\n",
    "        path = 'https://www.food.com/topic/'+letter\n",
    "        topics[letter] = {}\n",
    "        wait()\n",
    "\n",
    "        for link in scrape_me(path).links():\n",
    "            if 'topic/' in link['href']:\n",
    "                topics[letter][link['href']] = 1\n",
    "\n",
    "    with open('./scraped_urls/food_com_topics.json', 'w') as json_file:\n",
    "        json.dump(topics, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Food.com dictionary of recipes (either load or create)\n",
    "try:\n",
    "    with open('./scraped_urls/food_com_recipes.json', 'r') as json_file:\n",
    "            dnew = json.load(json_file)\n",
    "except:\n",
    "    dnew={}\n",
    "    for letter in topics:\n",
    "        for topic in topics[letter]:\n",
    "            dnew[topic] = []\n",
    "    with open('./scraped_urls/food_com_recipes.json', 'w') as json_file:\n",
    "        json.dump(dnew, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping https://www.food.com/topic/a1-sauce From 25 to 28\n",
      "Scraping https://www.food.com/topic/african From 22 to 25\n",
      "https://www.food.com/topic/agave-nectar is Complete.\n",
      "https://www.food.com/topic/alfredo-sauce is Complete.\n",
      "https://www.food.com/topic/ambrosia-salad is Complete.\n",
      "Scraping https://www.food.com/topic/american From 22 to 25\n",
      "Scraping https://www.food.com/topic/appetizers From 22 to 25\n",
      "Scraping https://www.food.com/topic/appetizers-cheese From 22 to 25\n",
      "https://www.food.com/topic/appetizers-finger-food is Complete.\n",
      "Scraping https://www.food.com/topic/appetizers-mushrooms From 22 to 25\n",
      "Scraping https://www.food.com/topic/appetizers-vegetarian From 22 to 25\n",
      "Scraping https://www.food.com/topic/apples From 22 to 25\n",
      "Scraping https://www.food.com/topic/apple-bread From 22 to 25\n",
      "Scraping https://www.food.com/topic/apple-cake From 22 to 25\n",
      "https://www.food.com/topic/apple-cobbler is Complete.\n",
      "Scraping https://www.food.com/topic/apple-crisp From 22 to 25\n",
      "Scraping https://www.food.com/topic/apple-dessert From 22 to 25\n",
      "Scraping https://www.food.com/topic/apple-muffin From 22 to 25\n",
      "Scraping https://www.food.com/topic/apple-pie From 22 to 25\n",
      "Scraping https://www.food.com/topic/apple-salad From 22 to 25\n",
      "https://www.food.com/topic/apple-tart is Complete.\n",
      "https://www.food.com/topic/apples-canning is Complete.\n",
      "Scraping https://www.food.com/topic/artichoke From 22 to 25\n",
      "Scraping https://www.food.com/topic/artichoke-dip From 22 to 25\n",
      "Scraping https://www.food.com/topic/asian From 22 to 25\n",
      "Scraping https://www.food.com/topic/asian-appetizer From 22 to 25\n",
      "Scraping https://www.food.com/topic/asian-chicken From 22 to 25\n",
      "Scraping https://www.food.com/topic/asian-noodle From 22 to 25\n",
      "Scraping https://www.food.com/topic/asian-rice From 22 to 25\n",
      "Scraping https://www.food.com/topic/asian-salad From 22 to 25\n",
      "Scraping https://www.food.com/topic/asian-salmon From 22 to 25\n",
      "Scraping https://www.food.com/topic/asian-sauce From 22 to 25\n",
      "Scraping https://www.food.com/topic/asian-shrimp From 22 to 25\n",
      "Scraping https://www.food.com/topic/asian-soup From 22 to 25\n",
      "Scraping https://www.food.com/topic/asian-stir-fry From 22 to 25\n",
      "Scraping https://www.food.com/topic/asparagus From 22 to 25\n",
      "Scraping https://www.food.com/topic/asparagus-appetizers From 22 to 25\n",
      "Scraping https://www.food.com/topic/asparagus-side-dish From 22 to 25\n",
      "https://www.food.com/topic/asparagus-soup is Complete.\n",
      "https://www.food.com/topic/asparagus-soups is Complete.\n",
      "Scraping https://www.food.com/topic/australian From 22 to 25\n",
      "Scraping https://www.food.com/topic/austrian From 22 to 25\n",
      "Scraping https://www.food.com/topic/avocado From 22 to 25\n",
      "https://www.food.com/topic/baba-ganoush is Complete.\n",
      "https://www.food.com/topic/baby-back-ribs is Complete.\n",
      "https://www.food.com/topic/baby-shower-food is Complete.\n",
      "Scraping https://www.food.com/topic/bacon From 22 to 25\n",
      "Scraping https://www.food.com/topic/bacon-breakfast From 22 to 25\n",
      "https://www.food.com/topic/bacon-eggs is Complete.\n",
      "https://www.food.com/topic/bacon-quiche is Complete.\n",
      "https://www.food.com/topic/bacon-sandwiches is Complete.\n",
      "Scraping https://www.food.com/topic/baked-beans From 22 to 25\n",
      "Scraping https://www.food.com/topic/baked-chicken From 22 to 25\n",
      "https://www.food.com/topic/baked-potato-soup is Complete.\n",
      "https://www.food.com/topic/baked-ziti is Complete.\n",
      "Scraping https://www.food.com/topic/baking From 22 to 25\n",
      "Scraping https://www.food.com/topic/banana-bread From 22 to 25\n",
      "Scraping https://www.food.com/topic/banana-cake From 22 to 25\n",
      "https://www.food.com/topic/banana-cookies is Complete.\n",
      "Scraping https://www.food.com/topic/banana-cream-pie From 22 to 25\n",
      "Scraping https://www.food.com/topic/banana-muffin From 22 to 25\n",
      "Scraping https://www.food.com/topic/banana-nut-bread From 22 to 25\n",
      "Scraping https://www.food.com/topic/banana-pudding From 22 to 25\n",
      "Scraping https://www.food.com/topic/bananas-smoothies From 22 to 25\n",
      "Scraping https://www.food.com/topic/bananas-desserts From 22 to 25\n",
      "Scraping https://www.food.com/topic/barbecue From 22 to 25\n",
      "https://www.food.com/topic/barbecue-beef is Complete.\n",
      "https://www.food.com/topic/barbecue-chicken is Complete.\n",
      "https://www.food.com/topic/chicken-breasts-barbecue is Complete.\n",
      "Scraping https://www.food.com/topic/barbecue-pork From 22 to 25\n",
      "Scraping https://www.food.com/topic/barbecue-sauce From 22 to 25\n",
      "Waiting for 8 Seconds.\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-82-bdd8d736442b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Scraping \"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mtopic\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\" From \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\" to \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtopics\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mletter\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtopic\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtopics\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mletter\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtopic\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mnum_pages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m                 \u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m                 \u001b[0mpage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscrape_me\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtopic\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"?pn=\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-2a286d26e52d>\u001b[0m in \u001b[0;36mwait\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Waiting for {x} Seconds.\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'\\r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Easy Page structure\n",
    "num_pages = 3\n",
    "for letter in topics:\n",
    "    for topic in topics[letter]:\n",
    "        \n",
    "        if topics[letter][topic] == 'end':\n",
    "            print(topic + \" is Complete.\")\n",
    "            continue\n",
    "        else:\n",
    "            start = topics[letter][topic]\n",
    "            stop = topics[letter][topic]+num_pages\n",
    "\n",
    "            print(\"Scraping \"+topic + \" From \" + str(start) + \" to \" + str(stop))\n",
    "            for i in range(topics[letter][topic], topics[letter][topic]+num_pages):\n",
    "                wait()\n",
    "                page = scrape_me(topic+\"?pn=\"+str(i)).links()\n",
    "                \n",
    "                if len(page) < 35:\n",
    "                    topics[letter][topic] = 'end'\n",
    "                    break\n",
    "                else:\n",
    "                    for link in page:\n",
    "                        if 'recipe/' in link['href']:\n",
    "                            if link['href'] not in dnew[topic]:\n",
    "                                dnew[topic].append(link['href'])\n",
    "                    \n",
    "                    # Save incrementally to avoid losing progress\n",
    "                    topics[letter][topic] += 1\n",
    "                    with open('./scraped_urls/food_com_topics.json', 'w') as json_file:\n",
    "                        json.dump(topics, json_file)\n",
    "                    with open('./scraped_urls/food_com_recipes.json', 'w') as json_file:\n",
    "                        json.dump(dnew, json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Bowl of Delicious"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create or load main dictionary\n",
    "try:\n",
    "    dnew = json.load(open(\"./scraped_urls/bowl_of_delicious_urls.json\"))\n",
    "except:\n",
    "    dnew = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for 8 Seconds..\r"
     ]
    }
   ],
   "source": [
    "for i in range(1, 22):\n",
    "    path = 'https://www.bowlofdelicious.com/category/recipes/page/'+str(i)\n",
    "    page = scrape_me(path).links()\n",
    "    wait()\n",
    "    \n",
    "    for link in page:\n",
    "        if 'class' in link.keys():\n",
    "            if 'entry-image-link' in link['class']:\n",
    "                dnew[link['href']] = link['href'].split('www.bowlofdelicious.com/')[1][:-1]\n",
    "                \n",
    "    with open(\"./scraped_urls/bowl_of_delicious_urls.json\", \"w\") as json_file:\n",
    "        json.dump(dnew, json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Closet Cooking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create or load main dictionary\n",
    "try:\n",
    "    dnew = json.load(open(\"./scraped_urls/closet_cooking_urls.json\"))\n",
    "except:\n",
    "    dnew = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recipes Scraped: 2440..\r"
     ]
    }
   ],
   "source": [
    "for i in range(1, 63):\n",
    "    path = 'https://www.closetcooking.com/category/recipe/page/'+str(i)\n",
    "    page = scrape_me(path).links()\n",
    "    wait()\n",
    "    \n",
    "    for link in page:\n",
    "        if 'class' in link.keys():\n",
    "            if 'entry-image-link' in link['class']:\n",
    "                dnew[link['href']] = link['href'].split('www.closetcooking.com/')[1][:-1]\n",
    "                \n",
    "    print(\"Recipes Scraped: \"+str(len(dnew)), end='\\r')\n",
    "               \n",
    "    with open(\"./scraped_urls/closet_cooking_urls.json\", \"w\") as json_file:\n",
    "        json.dump(dnew, json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Cookstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create or load main dictionary\n",
    "try:\n",
    "    dnew = json.load(open(\"./scraped_urls/cookstr_urls.json\"))\n",
    "except:\n",
    "    dnew = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Recipes Scraped from Cookstr: 840\n",
      "Total Recipes Scraped from Cookstr: 855\n",
      "Total Recipes Scraped from Cookstr: 870\n",
      "Total Recipes Scraped from Cookstr: 885\n",
      "Total Recipes Scraped from Cookstr: 900\n",
      "Total Recipes Scraped from Cookstr: 915\n",
      "Total Recipes Scraped from Cookstr: 930\n",
      "Total Recipes Scraped from Cookstr: 945\n",
      "Total Recipes Scraped from Cookstr: 960\n",
      "Total Recipes Scraped from Cookstr: 975\n",
      "Total Recipes Scraped from Cookstr: 990\n",
      "Total Recipes Scraped from Cookstr: 1005\n",
      "Total Recipes Scraped from Cookstr: 1020\n",
      "Total Recipes Scraped from Cookstr: 1035\n",
      "Total Recipes Scraped from Cookstr: 1050\n",
      "Total Recipes Scraped from Cookstr: 1065\n",
      "Total Recipes Scraped from Cookstr: 1080\n",
      "Total Recipes Scraped from Cookstr: 1095\n",
      "Total Recipes Scraped from Cookstr: 1110\n",
      "Total Recipes Scraped from Cookstr: 1125\n",
      "Total Recipes Scraped from Cookstr: 1140\n",
      "Total Recipes Scraped from Cookstr: 1155\n",
      "Total Recipes Scraped from Cookstr: 1170\n",
      "Total Recipes Scraped from Cookstr: 1185\n",
      "Total Recipes Scraped from Cookstr: 1200\n",
      "Total Recipes Scraped from Cookstr: 1215\n",
      "Total Recipes Scraped from Cookstr: 1230\n",
      "Total Recipes Scraped from Cookstr: 1245\n",
      "Total Recipes Scraped from Cookstr: 1260\n",
      "Total Recipes Scraped from Cookstr: 1275\n",
      "Total Recipes Scraped from Cookstr: 1290\n",
      "Total Recipes Scraped from Cookstr: 1305\n",
      "Total Recipes Scraped from Cookstr: 1320\n",
      "Total Recipes Scraped from Cookstr: 1335\n",
      "Total Recipes Scraped from Cookstr: 1350\n",
      "Total Recipes Scraped from Cookstr: 1365\n",
      "Total Recipes Scraped from Cookstr: 1380\n",
      "Total Recipes Scraped from Cookstr: 1395\n",
      "Total Recipes Scraped from Cookstr: 1410\n",
      "Total Recipes Scraped from Cookstr: 1425\n",
      "Total Recipes Scraped from Cookstr: 1440\n",
      "Total Recipes Scraped from Cookstr: 1455\n",
      "Total Recipes Scraped from Cookstr: 1470\n",
      "Total Recipes Scraped from Cookstr: 1485\n",
      "Total Recipes Scraped from Cookstr: 1500\n",
      "Total Recipes Scraped from Cookstr: 1515\n",
      "Total Recipes Scraped from Cookstr: 1530\n",
      "Total Recipes Scraped from Cookstr: 1545\n",
      "Total Recipes Scraped from Cookstr: 1560\n",
      "Total Recipes Scraped from Cookstr: 1575\n",
      "Total Recipes Scraped from Cookstr: 1590\n",
      "Total Recipes Scraped from Cookstr: 1605\n",
      "Total Recipes Scraped from Cookstr: 1620\n",
      "Total Recipes Scraped from Cookstr: 1635\n",
      "Total Recipes Scraped from Cookstr: 1650\n",
      "Total Recipes Scraped from Cookstr: 1665\n",
      "Total Recipes Scraped from Cookstr: 1680\n",
      "Total Recipes Scraped from Cookstr: 1695\n",
      "Total Recipes Scraped from Cookstr: 1710\n",
      "Total Recipes Scraped from Cookstr: 1725\n",
      "Total Recipes Scraped from Cookstr: 1740\n",
      "Total Recipes Scraped from Cookstr: 1755\n",
      "Total Recipes Scraped from Cookstr: 1770\n",
      "Total Recipes Scraped from Cookstr: 1785\n",
      "Total Recipes Scraped from Cookstr: 1800\n",
      "Total Recipes Scraped from Cookstr: 1815\n",
      "Total Recipes Scraped from Cookstr: 1830\n",
      "Total Recipes Scraped from Cookstr: 1845\n",
      "Total Recipes Scraped from Cookstr: 1860\n",
      "Total Recipes Scraped from Cookstr: 1875\n",
      "Total Recipes Scraped from Cookstr: 1890\n",
      "Total Recipes Scraped from Cookstr: 1905\n",
      "Total Recipes Scraped from Cookstr: 1920\n",
      "Total Recipes Scraped from Cookstr: 1935\n",
      "Total Recipes Scraped from Cookstr: 1950\n",
      "Total Recipes Scraped from Cookstr: 1965\n",
      "Total Recipes Scraped from Cookstr: 1980\n",
      "Total Recipes Scraped from Cookstr: 1995\n",
      "Total Recipes Scraped from Cookstr: 2010\n",
      "Total Recipes Scraped from Cookstr: 2025\n",
      "Total Recipes Scraped from Cookstr: 2040\n",
      "Total Recipes Scraped from Cookstr: 2055\n",
      "Total Recipes Scraped from Cookstr: 2070\n",
      "Total Recipes Scraped from Cookstr: 2085\n",
      "Total Recipes Scraped from Cookstr: 2100\n",
      "Total Recipes Scraped from Cookstr: 2115\n",
      "Total Recipes Scraped from Cookstr: 2130\n",
      "Total Recipes Scraped from Cookstr: 2145\n",
      "Total Recipes Scraped from Cookstr: 2160\n",
      "Total Recipes Scraped from Cookstr: 2175\n",
      "Total Recipes Scraped from Cookstr: 2190\n",
      "Total Recipes Scraped from Cookstr: 2205\n",
      "Total Recipes Scraped from Cookstr: 2220\n",
      "Total Recipes Scraped from Cookstr: 2235\n",
      "Total Recipes Scraped from Cookstr: 2250\n",
      "Total Recipes Scraped from Cookstr: 2265\n",
      "Total Recipes Scraped from Cookstr: 2280\n",
      "Total Recipes Scraped from Cookstr: 2295\n",
      "Total Recipes Scraped from Cookstr: 2310\n",
      "Total Recipes Scraped from Cookstr: 2325\n",
      "Total Recipes Scraped from Cookstr: 2340\n",
      "Total Recipes Scraped from Cookstr: 2355\n",
      "Total Recipes Scraped from Cookstr: 2370\n",
      "Total Recipes Scraped from Cookstr: 2385\n",
      "Total Recipes Scraped from Cookstr: 2400\n",
      "Total Recipes Scraped from Cookstr: 2415\n",
      "Total Recipes Scraped from Cookstr: 2430\n",
      "Total Recipes Scraped from Cookstr: 2445\n",
      "Total Recipes Scraped from Cookstr: 2460\n",
      "Total Recipes Scraped from Cookstr: 2475\n",
      "Total Recipes Scraped from Cookstr: 2490\n",
      "Total Recipes Scraped from Cookstr: 2505\n",
      "Total Recipes Scraped from Cookstr: 2520\n",
      "Total Recipes Scraped from Cookstr: 2535\n",
      "Total Recipes Scraped from Cookstr: 2550\n",
      "Total Recipes Scraped from Cookstr: 2565\n",
      "Total Recipes Scraped from Cookstr: 2580\n",
      "Total Recipes Scraped from Cookstr: 2595\n",
      "Total Recipes Scraped from Cookstr: 2610\n",
      "Total Recipes Scraped from Cookstr: 2625\n",
      "Total Recipes Scraped from Cookstr: 2640\n",
      "Total Recipes Scraped from Cookstr: 2655\n",
      "Total Recipes Scraped from Cookstr: 2670\n",
      "Total Recipes Scraped from Cookstr: 2685\n",
      "Total Recipes Scraped from Cookstr: 2700\n",
      "Total Recipes Scraped from Cookstr: 2715\n",
      "Total Recipes Scraped from Cookstr: 2730\n",
      "Total Recipes Scraped from Cookstr: 2745\n",
      "Total Recipes Scraped from Cookstr: 2760\n",
      "Total Recipes Scraped from Cookstr: 2775\n",
      "Total Recipes Scraped from Cookstr: 2790\n",
      "Total Recipes Scraped from Cookstr: 2805\n",
      "Total Recipes Scraped from Cookstr: 2820\n",
      "Total Recipes Scraped from Cookstr: 2835\n",
      "Total Recipes Scraped from Cookstr: 2850\n",
      "Total Recipes Scraped from Cookstr: 2865\n",
      "Total Recipes Scraped from Cookstr: 2880\n",
      "Total Recipes Scraped from Cookstr: 2895\n",
      "Total Recipes Scraped from Cookstr: 2910\n",
      "Total Recipes Scraped from Cookstr: 2925\n",
      "Total Recipes Scraped from Cookstr: 2940\n",
      "Total Recipes Scraped from Cookstr: 2955\n",
      "Total Recipes Scraped from Cookstr: 2970\n",
      "Total Recipes Scraped from Cookstr: 2985\n",
      "Total Recipes Scraped from Cookstr: 3000\n",
      "Total Recipes Scraped from Cookstr: 3015\n",
      "Total Recipes Scraped from Cookstr: 3030\n",
      "Total Recipes Scraped from Cookstr: 3045\n",
      "Total Recipes Scraped from Cookstr: 3060\n",
      "Total Recipes Scraped from Cookstr: 3075\n",
      "Total Recipes Scraped from Cookstr: 3090\n",
      "Total Recipes Scraped from Cookstr: 3105\n",
      "Total Recipes Scraped from Cookstr: 3120\n",
      "Total Recipes Scraped from Cookstr: 3135\n",
      "Total Recipes Scraped from Cookstr: 3150\n",
      "Total Recipes Scraped from Cookstr: 3165\n",
      "Total Recipes Scraped from Cookstr: 3180\n",
      "Total Recipes Scraped from Cookstr: 3195\n",
      "Total Recipes Scraped from Cookstr: 3210\n",
      "Total Recipes Scraped from Cookstr: 3225\n",
      "Total Recipes Scraped from Cookstr: 3240\n",
      "Total Recipes Scraped from Cookstr: 3255\n",
      "Total Recipes Scraped from Cookstr: 3270\n",
      "Total Recipes Scraped from Cookstr: 3285\n",
      "Total Recipes Scraped from Cookstr: 3300\n",
      "Total Recipes Scraped from Cookstr: 3315\n",
      "Total Recipes Scraped from Cookstr: 3330\n",
      "Total Recipes Scraped from Cookstr: 3345\n",
      "Total Recipes Scraped from Cookstr: 3360\n",
      "Total Recipes Scraped from Cookstr: 3375\n",
      "Total Recipes Scraped from Cookstr: 3390\n",
      "Total Recipes Scraped from Cookstr: 3405\n",
      "Total Recipes Scraped from Cookstr: 3420\n",
      "Total Recipes Scraped from Cookstr: 3435\n",
      "Total Recipes Scraped from Cookstr: 3450\n",
      "Total Recipes Scraped from Cookstr: 3465\n",
      "Total Recipes Scraped from Cookstr: 3480\n",
      "Total Recipes Scraped from Cookstr: 3495\n",
      "Total Recipes Scraped from Cookstr: 3510\n",
      "Total Recipes Scraped from Cookstr: 3525\n",
      "Total Recipes Scraped from Cookstr: 3540\n",
      "Total Recipes Scraped from Cookstr: 3555\n",
      "Total Recipes Scraped from Cookstr: 3570\n",
      "Total Recipes Scraped from Cookstr: 3585\n",
      "Total Recipes Scraped from Cookstr: 3600\n",
      "Total Recipes Scraped from Cookstr: 3615\n",
      "Total Recipes Scraped from Cookstr: 3630\n",
      "Total Recipes Scraped from Cookstr: 3645\n",
      "Total Recipes Scraped from Cookstr: 3660\n",
      "Total Recipes Scraped from Cookstr: 3675\n",
      "Total Recipes Scraped from Cookstr: 3690\n",
      "Total Recipes Scraped from Cookstr: 3705\n",
      "Total Recipes Scraped from Cookstr: 3720\n",
      "Total Recipes Scraped from Cookstr: 3735\n",
      "Total Recipes Scraped from Cookstr: 3750\n",
      "Total Recipes Scraped from Cookstr: 3765\n",
      "Total Recipes Scraped from Cookstr: 3780\n",
      "Total Recipes Scraped from Cookstr: 3795\n",
      "Total Recipes Scraped from Cookstr: 3810\n",
      "Total Recipes Scraped from Cookstr: 3825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Recipes Scraped from Cookstr: 3840\n",
      "Total Recipes Scraped from Cookstr: 3855\n",
      "Total Recipes Scraped from Cookstr: 3870\n",
      "Total Recipes Scraped from Cookstr: 3885\n",
      "Total Recipes Scraped from Cookstr: 3900\n",
      "Total Recipes Scraped from Cookstr: 3915\n",
      "Total Recipes Scraped from Cookstr: 3930\n",
      "Total Recipes Scraped from Cookstr: 3945\n",
      "Total Recipes Scraped from Cookstr: 3960\n",
      "Total Recipes Scraped from Cookstr: 3975\n",
      "Total Recipes Scraped from Cookstr: 3990\n",
      "Total Recipes Scraped from Cookstr: 4005\n",
      "Total Recipes Scraped from Cookstr: 4020\n",
      "Total Recipes Scraped from Cookstr: 4035\n",
      "Total Recipes Scraped from Cookstr: 4050\n",
      "Total Recipes Scraped from Cookstr: 4065\n",
      "Total Recipes Scraped from Cookstr: 4080\n",
      "Total Recipes Scraped from Cookstr: 4095\n",
      "Total Recipes Scraped from Cookstr: 4110\n",
      "Total Recipes Scraped from Cookstr: 4125\n",
      "Total Recipes Scraped from Cookstr: 4140\n",
      "Total Recipes Scraped from Cookstr: 4155\n",
      "Total Recipes Scraped from Cookstr: 4170\n",
      "Total Recipes Scraped from Cookstr: 4185\n",
      "Total Recipes Scraped from Cookstr: 4200\n",
      "Total Recipes Scraped from Cookstr: 4215\n",
      "Total Recipes Scraped from Cookstr: 4230\n",
      "Total Recipes Scraped from Cookstr: 4245\n",
      "Total Recipes Scraped from Cookstr: 4260\n",
      "Total Recipes Scraped from Cookstr: 4275\n",
      "Total Recipes Scraped from Cookstr: 4290\n",
      "Total Recipes Scraped from Cookstr: 4305\n",
      "Total Recipes Scraped from Cookstr: 4320\n",
      "Total Recipes Scraped from Cookstr: 4335\n",
      "Total Recipes Scraped from Cookstr: 4350\n",
      "Total Recipes Scraped from Cookstr: 4365\n",
      "Total Recipes Scraped from Cookstr: 4380\n",
      "Total Recipes Scraped from Cookstr: 4395\n",
      "Total Recipes Scraped from Cookstr: 4410\n",
      "Total Recipes Scraped from Cookstr: 4425\n",
      "Total Recipes Scraped from Cookstr: 4440\n",
      "Total Recipes Scraped from Cookstr: 4455\n",
      "Total Recipes Scraped from Cookstr: 4470\n",
      "Total Recipes Scraped from Cookstr: 4485\n",
      "Total Recipes Scraped from Cookstr: 4500\n",
      "Total Recipes Scraped from Cookstr: 4515\n",
      "Total Recipes Scraped from Cookstr: 4530\n",
      "Total Recipes Scraped from Cookstr: 4545\n",
      "Total Recipes Scraped from Cookstr: 4560\n",
      "Total Recipes Scraped from Cookstr: 4575\n",
      "Total Recipes Scraped from Cookstr: 4590\n",
      "Total Recipes Scraped from Cookstr: 4605\n",
      "Total Recipes Scraped from Cookstr: 4620\n",
      "Total Recipes Scraped from Cookstr: 4635\n",
      "Total Recipes Scraped from Cookstr: 4650\n",
      "Total Recipes Scraped from Cookstr: 4665\n",
      "Total Recipes Scraped from Cookstr: 4680\n",
      "Total Recipes Scraped from Cookstr: 4695\n",
      "Total Recipes Scraped from Cookstr: 4710\n",
      "Total Recipes Scraped from Cookstr: 4725\n",
      "Total Recipes Scraped from Cookstr: 4740\n",
      "Total Recipes Scraped from Cookstr: 4755\n",
      "Total Recipes Scraped from Cookstr: 4770\n",
      "Total Recipes Scraped from Cookstr: 4785\n",
      "Total Recipes Scraped from Cookstr: 4800\n",
      "Total Recipes Scraped from Cookstr: 4815\n",
      "Total Recipes Scraped from Cookstr: 4830\n",
      "Total Recipes Scraped from Cookstr: 4845\n",
      "Total Recipes Scraped from Cookstr: 4860\n",
      "Total Recipes Scraped from Cookstr: 4875\n",
      "Total Recipes Scraped from Cookstr: 4890\n",
      "Total Recipes Scraped from Cookstr: 4905\n",
      "Total Recipes Scraped from Cookstr: 4920\n",
      "Total Recipes Scraped from Cookstr: 4935\n",
      "Total Recipes Scraped from Cookstr: 4950\n",
      "Total Recipes Scraped from Cookstr: 4965\n",
      "Total Recipes Scraped from Cookstr: 4980\n",
      "Total Recipes Scraped from Cookstr: 4995\n",
      "Total Recipes Scraped from Cookstr: 5010\n",
      "Total Recipes Scraped from Cookstr: 5025\n",
      "Total Recipes Scraped from Cookstr: 5040\n",
      "Total Recipes Scraped from Cookstr: 5055\n",
      "Total Recipes Scraped from Cookstr: 5070\n",
      "Total Recipes Scraped from Cookstr: 5085\n",
      "Total Recipes Scraped from Cookstr: 5100\n",
      "Total Recipes Scraped from Cookstr: 5115\n",
      "Total Recipes Scraped from Cookstr: 5130\n",
      "Total Recipes Scraped from Cookstr: 5145\n",
      "Total Recipes Scraped from Cookstr: 5160\n",
      "Total Recipes Scraped from Cookstr: 5175\n",
      "Total Recipes Scraped from Cookstr: 5190\n",
      "Total Recipes Scraped from Cookstr: 5205\n",
      "Total Recipes Scraped from Cookstr: 5220\n",
      "Total Recipes Scraped from Cookstr: 5235\n",
      "Total Recipes Scraped from Cookstr: 5250\n",
      "Total Recipes Scraped from Cookstr: 5265\n",
      "Total Recipes Scraped from Cookstr: 5280\n",
      "Total Recipes Scraped from Cookstr: 5295\n",
      "Total Recipes Scraped from Cookstr: 5310\n",
      "Total Recipes Scraped from Cookstr: 5325\n",
      "Total Recipes Scraped from Cookstr: 5340\n",
      "Total Recipes Scraped from Cookstr: 5355\n",
      "Total Recipes Scraped from Cookstr: 5370\n",
      "Total Recipes Scraped from Cookstr: 5385\n",
      "Total Recipes Scraped from Cookstr: 5400\n",
      "Total Recipes Scraped from Cookstr: 5415\n",
      "Total Recipes Scraped from Cookstr: 5430\n",
      "Total Recipes Scraped from Cookstr: 5445\n",
      "Total Recipes Scraped from Cookstr: 5460\n",
      "Total Recipes Scraped from Cookstr: 5475\n",
      "Total Recipes Scraped from Cookstr: 5490\n",
      "Total Recipes Scraped from Cookstr: 5505\n",
      "Total Recipes Scraped from Cookstr: 5520\n",
      "Total Recipes Scraped from Cookstr: 5535\n",
      "Total Recipes Scraped from Cookstr: 5550\n",
      "Total Recipes Scraped from Cookstr: 5565\n",
      "Total Recipes Scraped from Cookstr: 5580\n",
      "Total Recipes Scraped from Cookstr: 5595\n",
      "Total Recipes Scraped from Cookstr: 5610\n",
      "Total Recipes Scraped from Cookstr: 5625\n",
      "Total Recipes Scraped from Cookstr: 5640\n",
      "Total Recipes Scraped from Cookstr: 5655\n",
      "Total Recipes Scraped from Cookstr: 5670\n",
      "Total Recipes Scraped from Cookstr: 5685\n",
      "Total Recipes Scraped from Cookstr: 5700\n",
      "Total Recipes Scraped from Cookstr: 5715\n",
      "Total Recipes Scraped from Cookstr: 5730\n",
      "Total Recipes Scraped from Cookstr: 5745\n",
      "Total Recipes Scraped from Cookstr: 5760\n",
      "Total Recipes Scraped from Cookstr: 5775\n",
      "Total Recipes Scraped from Cookstr: 5790\n",
      "Total Recipes Scraped from Cookstr: 5805\n",
      "Total Recipes Scraped from Cookstr: 5820\n",
      "Total Recipes Scraped from Cookstr: 5835\n",
      "Total Recipes Scraped from Cookstr: 5850\n",
      "Total Recipes Scraped from Cookstr: 5865\n",
      "Total Recipes Scraped from Cookstr: 5880\n",
      "Total Recipes Scraped from Cookstr: 5895\n",
      "Total Recipes Scraped from Cookstr: 5910\n",
      "Total Recipes Scraped from Cookstr: 5925\n",
      "Total Recipes Scraped from Cookstr: 5940\n",
      "Total Recipes Scraped from Cookstr: 5955\n",
      "Total Recipes Scraped from Cookstr: 5970\n",
      "Total Recipes Scraped from Cookstr: 5985\n",
      "Total Recipes Scraped from Cookstr: 6000\n",
      "Total Recipes Scraped from Cookstr: 6015\n",
      "Total Recipes Scraped from Cookstr: 6030\n",
      "Total Recipes Scraped from Cookstr: 6045\n",
      "Total Recipes Scraped from Cookstr: 6060\n",
      "Total Recipes Scraped from Cookstr: 6075\n",
      "Total Recipes Scraped from Cookstr: 6090\n",
      "Total Recipes Scraped from Cookstr: 6105\n",
      "Total Recipes Scraped from Cookstr: 6120\n",
      "Total Recipes Scraped from Cookstr: 6135\n",
      "Total Recipes Scraped from Cookstr: 6150\n",
      "Total Recipes Scraped from Cookstr: 6165\n",
      "Total Recipes Scraped from Cookstr: 6180\n",
      "Total Recipes Scraped from Cookstr: 6195\n",
      "Total Recipes Scraped from Cookstr: 6210\n",
      "Total Recipes Scraped from Cookstr: 6225\n",
      "Total Recipes Scraped from Cookstr: 6240\n",
      "Total Recipes Scraped from Cookstr: 6255\n",
      "Total Recipes Scraped from Cookstr: 6270\n",
      "Total Recipes Scraped from Cookstr: 6285\n",
      "Total Recipes Scraped from Cookstr: 6300\n",
      "Total Recipes Scraped from Cookstr: 6315\n",
      "Total Recipes Scraped from Cookstr: 6330\n",
      "Total Recipes Scraped from Cookstr: 6345\n",
      "Total Recipes Scraped from Cookstr: 6360\n",
      "Total Recipes Scraped from Cookstr: 6375\n",
      "Total Recipes Scraped from Cookstr: 6390\n",
      "Total Recipes Scraped from Cookstr: 6405\n",
      "Total Recipes Scraped from Cookstr: 6420\n",
      "Waiting for 9 Seconds.\r"
     ]
    }
   ],
   "source": [
    "for i in range(57, 430):\n",
    "    path = 'https://www.cookstr.com/recipes/page/'+str(i)\n",
    "    page = scrape_me(path).links()\n",
    "    print(\"Total Recipes Scraped from Cookstr: \" + str(len(dnew)))\n",
    "    wait()\n",
    "    \n",
    "    for link in page:\n",
    "        if 'class' in link.keys():\n",
    "            if 'more' in link['class']:\n",
    "                dnew['https://www.cookstr.com'+link['href']] = link['href'].split('recipes/')[1]\n",
    "    \n",
    "    with open(\"./scraped_urls/cookstr_urls.json\", \"w\") as json_file:\n",
    "        json.dump(dnew, json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Cookie and Kate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    dnew = json.load(open(\"./scraped_urls/cookie_kate_urls.json\"))\n",
    "except:\n",
    "    dnew = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "categories = []\n",
    "for link in scrape_me('https://cookieandkate.com/recipes/').links():\n",
    "    if link['href'] not in categories:\n",
    "        if '/category/food-recipes' in link['href']:\n",
    "            categories.append(link['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping https://cookieandkate.com/category/food-recipes/appetizers/\n",
      "Scraping https://cookieandkate.com/category/food-recipes/baked-goods/\n",
      "Scraping https://cookieandkate.com/category/food-recipes/breakfast/\n",
      "Scraping https://cookieandkate.com/category/food-recipes/cookies/\n",
      "Scraping https://cookieandkate.com/category/food-recipes/dessert/\n",
      "Scraping https://cookieandkate.com/category/food-recipes/condiments-dips-sauces/\n",
      "Scraping https://cookieandkate.com/category/food-recipes/entrees/\n",
      "Scraping https://cookieandkate.com/category/food-recipes/drinks/\n",
      "Scraping https://cookieandkate.com/category/food-recipes/salads/\n",
      "Scraping https://cookieandkate.com/category/food-recipes/side-dishes/\n",
      "Scraping https://cookieandkate.com/category/food-recipes/healthy-snacks/\n",
      "Scraping https://cookieandkate.com/category/food-recipes/soups-and-stews/\n",
      "Scraping https://cookieandkate.com/category/food-recipes/reader-favorites/\n",
      "Scraping https://cookieandkate.com/category/food-recipes/budget-friendly/\n",
      "Scraping https://cookieandkate.com/category/food-recipes/pack-for-lunch/\n",
      "Scraping https://cookieandkate.com/category/food-recipes/pantry-friendly/\n",
      "Scraping https://cookieandkate.com/category/food-recipes/easy-weeknight-dinners/\n",
      "Waiting for 4 Seconds.\r"
     ]
    }
   ],
   "source": [
    "for c in categories:\n",
    "    print(\"Scraping \"+c)\n",
    "    c_name = c.split('category/food-recipes/')[1][:-1]\n",
    "    dnew[c_name] = []\n",
    "    for i in range(1, 50):\n",
    "        path = c+'/page/'+str(i)\n",
    "        page = scrape_me(path).links()\n",
    "        wait()\n",
    "        \n",
    "        if len(page) < 106:\n",
    "            break\n",
    "    \n",
    "        else:\n",
    "            end = 85-(125-len(page))\n",
    "            if end > 65:\n",
    "                for link in page[65:end]:\n",
    "                    dnew[c_name].append(link['href'])\n",
    "        with open(\"./scraped_urls/cookie_kate_urls.json\", \"w\") as json_file:\n",
    "            json.dump(dnew, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
