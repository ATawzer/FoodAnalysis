{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from recipe_scrapers import scrape_me\n",
    "import time\n",
    "import random\n",
    "import json\n",
    "import pymongo\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wait():\n",
    "    \n",
    "    x = random.randrange(1, 200, 1)/100\n",
    "    print(f\"Waiting for {x} Seconds.\", end='\\r')\n",
    "    time.sleep(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Db Information\n",
    "client = pymongo.MongoClient(\"mongodb://localhost:27017/\")\n",
    "db = client['food_analysis']\n",
    "urls = db['urls']\n",
    "recipes = db['recipes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_id': 'https://www.food.com/recipe/elephants-mudbath-217537',\n",
       "  'name': 'elephants-mudbath',\n",
       "  'read': True,\n",
       "  'type': ['african'],\n",
       "  'source': 'food_com',\n",
       "  'website_id': '217537'},\n",
       " {'_id': 'https://www.food.com/recipe/olive-garden-asparagus-with-lemon-and-minced-onions-351063',\n",
       "  'name': 'olive-garden-asparagus-with-lemon-and-minced-onions',\n",
       "  'read': True,\n",
       "  'type': ['asparagus', 'asparagus-side-dish'],\n",
       "  'source': 'food_com',\n",
       "  'website_id': '351063'},\n",
       " {'_id': 'https://www.food.com/recipe/quick-pizza-sauce-with-fennel-409930',\n",
       "  'name': 'quick-pizza-sauce-with-fennel',\n",
       "  'read': True,\n",
       "  'type': ['pizza-sauce'],\n",
       "  'source': 'food_com',\n",
       "  'website_id': '409930'}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(urls.find({\"read\":True}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraper\n",
    "Take the url database and start retrieving the actual recipe contents to store in a new database dedicated to the recipes. Given that this database will form the basis for an actual app and analysis the key unique id will be generated by Mongo and keep close tabs with the url database to ensure no read recipes are reread."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "eligible_urls = [x[\"_id\"] for x in list(urls.find({\"read\":False}, {\"_id\":1}))]\n",
    "eligible_urls = sorted(eligible_urls, key = lambda x: random.random())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4b84d2581f34170a8622bf972895d5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=220842.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.food.com/recipe/quick-pizza-sauce-with-fennel-409930\n",
      "https://www.food.com/recipe/elephants-mudbath-217537\n",
      "https://www.food.com/recipe/olive-garden-asparagus-with-lemon-and-minced-onions-351063\n",
      "//www.foodnetwork.com/recipes/aaron-mccargo-jr/apple-cranberry-bread-pudding-recipe-1946155\n",
      "Waiting for 0.66 Seconds.\r"
     ]
    },
    {
     "ename": "WebsiteNotImplementedError",
     "evalue": "Website () is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\atawz\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\recipe_scrapers\\__init__.py\u001b[0m in \u001b[0;36mscrape_me\u001b[1;34m(url_path, **options)\u001b[0m\n\u001b[0;32m    224\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 225\u001b[1;33m         \u001b[0mscraper\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSCRAPERS\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mhost_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    226\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: ''",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mWebsiteNotImplementedError\u001b[0m                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-9f3acdfbdd07>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m# Pause and then scrape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mscraper\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscrape_me\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;31m# Attempt each piece of data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\atawz\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\recipe_scrapers\\__init__.py\u001b[0m in \u001b[0;36mscrape_me\u001b[1;34m(url_path, **options)\u001b[0m\n\u001b[0;32m    225\u001b[0m         \u001b[0mscraper\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSCRAPERS\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mhost_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 227\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mWebsiteNotImplementedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhost_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mscraper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mWebsiteNotImplementedError\u001b[0m: Website () is not supported"
     ]
    }
   ],
   "source": [
    "for url in tqdm(eligible_urls):\n",
    "    \n",
    "    # Obtain existing data\n",
    "    print(url)\n",
    "    row = list(urls.find({\"_id\":url}))[0]\n",
    "    \n",
    "    # Pause and then scrape\n",
    "    wait()\n",
    "    scraper = scrape_me(url)\n",
    "    \n",
    "    # Attempt each piece of data\n",
    "    \n",
    "    # Title\n",
    "    try:\n",
    "        title = scraper.title()\n",
    "    except:\n",
    "        try:\n",
    "            title = row['name']\n",
    "        except:\n",
    "            title = None\n",
    "            \n",
    "    # Total Time\n",
    "    try:\n",
    "        total_time = scraper.total_time()\n",
    "    except:\n",
    "        total_time = None\n",
    "        \n",
    "    # Yields\n",
    "    try:\n",
    "        yields = scraper.yields()\n",
    "    except:\n",
    "        yields = None\n",
    "        \n",
    "    # Ingredients\n",
    "    try:\n",
    "        ingredients = scraper.ingredients()\n",
    "    except:\n",
    "        ingredients = []\n",
    "        \n",
    "    # Instructions\n",
    "    try:\n",
    "        instructions = scraper.instructions()\n",
    "    except:\n",
    "        instructions = []\n",
    "        \n",
    "    # Image\n",
    "    try:\n",
    "        image = scraper.image()\n",
    "    except:\n",
    "        image = None\n",
    "        \n",
    "    # Ratings\n",
    "    try:\n",
    "        rating = scraper.ratings()\n",
    "    except:\n",
    "        rating = None\n",
    "        \n",
    "    # Author\n",
    "    try:\n",
    "        author = scraper.author()\n",
    "    except:\n",
    "        try:\n",
    "            author = row['author']\n",
    "        except:\n",
    "            author = None\n",
    "            \n",
    "    # Reviews\n",
    "    try:\n",
    "        reviews = scraper.reviews()\n",
    "    except:\n",
    "        reviews = None\n",
    "    \n",
    "    # Insert new data\n",
    "    recipes.insert_one({\"title\":title,\n",
    "                        \"total_time\":total_time,\n",
    "                        \"yields\":yields,\n",
    "                        \"ingredients\":ingredients,\n",
    "                        \"instructions\":instructions,\n",
    "                        \"image\":image,\n",
    "                        \"rating\":rating,\n",
    "                        \"author\":author,\n",
    "                        \"reviews\":reviews,\n",
    "                        \"source\":row['source'],\n",
    "                        \"url\":row[\"_id\"]})\n",
    "    \n",
    "    # Mark as read\n",
    "    query = {\"_id\":url}\n",
    "    newvalues = {\"$set\":{\"read\":True}}\n",
    "    urls.update_one(query, newvalues)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
